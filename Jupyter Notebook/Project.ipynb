{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    " File name: Project.ipynb\n",
    " Author: Meljohn Ugaddan\n",
    " Date created: 3/12/2021\n",
    " Date last modified: 4/12/2021\n",
    " Python Version: 3.8\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "import re \n",
    "\n",
    "# STATE TRANSITION\n",
    "nextState = {0: {0:0 ,1:1 , 2:2 , 3:8 , 4:0 , 11:11,6:6 ,5:5 ,7:7 ,8:8  ,9:9 ,10:10},\n",
    "             1: {0:0 ,1:1 , 2:11, 3:3 , 4:0 , 11:11,6:6 ,5:5 ,7:7 ,8:8  ,9:9 ,10:10},\n",
    "             2: {0:0 ,1:11, 2:0 , 3:0 , 4:0 , 11:0 ,6:0 ,5:0 ,7:0 ,8:0  ,9:0 ,10:0 },\n",
    "             3: {0:0 ,1:4 , 2:2 , 3:0 , 4:4 , 11:11,6:0 ,5:0 ,7:7 ,8:8  ,9:9 ,10:10},\n",
    "             11:{0:0 ,1:11, 2:2 , 3:4 , 4:4 , 11:7 ,6:0 ,5:0 ,7:7 ,8:8  ,9:9 ,10:10},\n",
    "             4: {0:0 ,1:4 , 2:0 , 3:0 , 4:0 , 11:11,6:6 ,5:5 ,7:7 ,8:8  ,9:9 ,10:10},\n",
    "             5: {0:0 ,1:1 , 2:2 , 3:3 , 4:0 , 11:11,6:6 ,5:5 ,7:7 ,8:8  ,9:9 ,10:10},\n",
    "             6: {0:0 ,1:1 , 2:2 , 3:3 , 4:0 , 11:11,6:7 ,5:5 ,7:7 ,8:8  ,9:9 ,10:10},\n",
    "             7: {0:7 ,1:7 , 2:2 , 3:7 , 4:7 , 11:11,6:7 ,5:7 ,7:7 ,8:7  ,9:7 ,10:7 },\n",
    "             8: {0:0 ,1:1 , 2:2 , 3:8 , 4:0 , 11:11,6:6 ,5:5 ,7:7 ,8:8  ,9:9 ,10:10},\n",
    "             9 :{0:9 ,1:9 , 2:9 , 3:9 , 4:9 , 11:9 ,6:9 ,5:9 ,7:9 ,8:9  ,9:0 ,10:9 },\n",
    "             10:{0:10,1:10, 2:10, 3:10, 4:10, 11:10,6:10,5:10,7:10,8:10 ,9:9 ,10:0 }}\n",
    "\n",
    "# CLASS FOR EACH TOKEN\n",
    "class Token:\n",
    "    id = ''\n",
    "    idString = ''\n",
    "    lexeme = ''\n",
    "        \n",
    "    def __init__(self, id, idString, lexeme): \n",
    "        self.id = id \n",
    "        self.idString = idString\n",
    "        self.lexeme = lexeme\n",
    "        \n",
    "## THE HEART OF THE PROGRAM\n",
    "class LexicalAnalyzer:\n",
    "    state = 0\n",
    "    text = '' # SPECIAL CHARACTER FOR \n",
    "    CheckIllegalChar = re.compile(r\"[<>{}[\\]~`^!:]\") # VARIABLE FOR CHECKING  SPECIAL CHARACTER FROM THE FILE\n",
    "    FileName = 'samp1.txt'\n",
    "    lastRead = 0\n",
    "    notFirstRead = False\n",
    "    prevState = None\n",
    "    \n",
    "    # THIS OBJECT IS FOR DYNAMIC CALLING OF CHARACTERS\n",
    "    stringObj = {\n",
    "        \"=\" : \"EQUAL\",\n",
    "        \"*\" : \"MULT\",\n",
    "        \"**\" : \"EXP\",\n",
    "        \"(\" : \"LPAREN\",\n",
    "        \")\" : \"RPAREN\",\n",
    "        \";\" : \"SCOLON\",\n",
    "        \",\" : \"COMMA\",\n",
    "        \"%\" : \"MODULO\",\n",
    "        \"+\" : \"PLUS\",\n",
    "        \"-\" : \"MINUS\",\n",
    "        \"/\" : \"DIV\",\n",
    "    }\n",
    "    \n",
    "    token = []\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.reset()\n",
    "        self.FileName = name\n",
    "    \n",
    "    def reset(self):\n",
    "        self.token = []\n",
    "        \n",
    "    def resetTextAndState(self):\n",
    "        lastRead = 0\n",
    "        notFirstRead = False\n",
    "        state = 0\n",
    "        text = ''\n",
    "        NumberDoesntHaveE = True\n",
    "        NumberDoesntHaveDot = True\n",
    "        \n",
    "    def check_character(self, c ,currentState):\n",
    "        if(c.isdigit() ):\n",
    "            self.state = 1\n",
    "        elif(c==\"(\"):\n",
    "            self.state = 0\n",
    "        elif(c==\")\"):\n",
    "            self.state= 0\n",
    "        elif(c==\";\"):\n",
    "            self.state = 0\n",
    "        elif(c==\",\"):\n",
    "            self.state = 0\n",
    "        elif(c.lower() =='e'):\n",
    "            self.state = 3\n",
    "        elif(c =='.'):\n",
    "            self.state = 2\n",
    "        elif(c==\"=\"):\n",
    "            self.state = 0\n",
    "        elif(c==\"%\"):\n",
    "            self.state = 0\n",
    "        elif(c==\"+\" or c==\"-\"):\n",
    "            self.state= 4\n",
    "        elif(c==\"*\"):\n",
    "            self.state = 5\n",
    "        elif(c==\"/\"):\n",
    "            self.state = 6\n",
    "        elif(c==\"#\"):\n",
    "            self.state= 7\n",
    "        elif(c.isalpha() ):\n",
    "            self.state= 8 \n",
    "        elif(c=='\"'):\n",
    "            self.state= 9\n",
    "        elif(c==\"'\"):\n",
    "            self.state= 10\n",
    "        else:\n",
    "            # THIS CODE ALLOW TO TERMINATE SPACE BETWEEN NUMBER\n",
    "            if(currentState==1):\n",
    "                self.state= 0\n",
    "            # ALLOW SPACES TO STRING\n",
    "            elif(currentState==9 or currentState== 10):\n",
    "                self.state=0\n",
    "            # THIS CODE ALLOW TO TERMINATE SPACE BETWEEN IDENTIFIER\n",
    "            elif(currentState==8):\n",
    "                self.state=0\n",
    "            # THE NULL STATE WILL BE SKIP IN THE LOOP\n",
    "            else:\n",
    "                self.state = None\n",
    "            \n",
    "\n",
    "    def process_token(self):       \n",
    "        with open(self.FileName) as f:\n",
    "            # GET THE LAST READ LINE\n",
    "            if(self.notFirstRead):\n",
    "                self.text = ''\n",
    "                self.state= 0\n",
    "                c = f.read(self.lastRead)\n",
    "                self.notFirstRead = False\n",
    "            currentState = 0\n",
    "            while True:\n",
    "                c = f.read(1)\n",
    "                self.lastRead += 1 \n",
    "                \n",
    "                if not c:\n",
    "                    # CHECK IF THERE IS PREV STATE\n",
    "                    token = self.checkPrevState(0,c);\n",
    "                    if(token != None):\n",
    "                        return token\n",
    "                    return Token(\"EOF\",\"End-of-file\",\"end-of-file token\")\n",
    "                    break\n",
    "                    \n",
    "                self.check_character(c,currentState)\n",
    "                \n",
    "                ##### CONDITION FOR SKIPPING SPACES EXCLUDING IF THE STATE IS :\n",
    "                ## 10 (STRING) , 9(STRING) , 1 (NUMBER) and 8 (IDENTIFIER)\n",
    "                if(self.state== None ):\n",
    "                    if(self.CheckIllegalChar.search(c) and currentState!=7):\n",
    "                        self.notFirstRead = True\n",
    "                        return Token(\"ERROR\",\"ERROR\",\"ILLEGAL CHARACTER\")\n",
    "                    \n",
    "                    # THIS IS FOR COMMENT STATE\n",
    "                    if(c==\"\\n\" and  self.prevState == 7):\n",
    "                        self.prevState = 7\n",
    "                        currentState = 0\n",
    "                    continue\n",
    "                #FOR UNTERMINATED STRING\n",
    "                if(c==\"\\n\" and  (currentState == 9 or currentState == 10)):\n",
    "                        self.notFirstRead = True\n",
    "                        return Token(\"ERROR\",\"ERROR\",\"UNTERMINATED STRING\")\n",
    "                    \n",
    "                # Transition\n",
    "                self.prevState = currentState\n",
    "                currentState = nextState[currentState][self.state]\n",
    "                \n",
    "                # FOR SINGLE CHAR LEXEME\n",
    "                if(currentState==0):\n",
    "                    # CHECK IF THERE IS PREV STATE\n",
    "                    token = self.checkPrevState(currentState,c);\n",
    "                    if(token != None):\n",
    "                        return token\n",
    "                    self.notFirstRead = True\n",
    "                    return Token(self.stringObj[c],self.stringObj[c],c)\n",
    "                \n",
    "                ########### FOR THE SUCCEEDING PART OF THIS CODE, THIS PART IS FOR APPENDING CHARACTER EACH STRING FOR..\n",
    "                ###  STATE THAT HAS MANY CHARACTER e.g, Number, String, Identifier or Others\n",
    "                # ASTERISK\n",
    "                elif(currentState==5):\n",
    "                    # CHECK IF THERE IS PREV STATE\n",
    "                    token = self.checkPrevState(currentState,c);\n",
    "                    if(token != None):\n",
    "                        return token\n",
    "                    if(self.prevState==5):\n",
    "                        self.notFirstRead = True\n",
    "                        return Token(self.stringObj[\"**\"],self.stringObj[\"**\"],\"**\")\n",
    "                # FOR SLASH\n",
    "                elif(currentState==6):\n",
    "                    # CHECK IF THERE IS PREV STATE\n",
    "                    token = self.checkPrevState(currentState,c);\n",
    "                    if(token != None):\n",
    "                        return token\n",
    "                # FOR IDENTIFIER\n",
    "                elif(currentState==8): \n",
    "                    if(self.prevState ==11):\n",
    "                        self.notFirstRead = True\n",
    "                        self.prevState = 0\n",
    "                        return Token(\"ERROR\",\"ERROR\",\"BADLY FORMED NUMBER\")\n",
    "                    # CHECK IF THERE IS PREV STATE\n",
    "                    token = self.checkPrevState(currentState,c);\n",
    "                    if(token != None):\n",
    "                        return token\n",
    "                    \n",
    "                    self.text += c\n",
    "                # FOR DOUBLE QUOTE STRING\n",
    "                elif(currentState==9): \n",
    "                    # CHECK IF THERE IS PREV STATE\n",
    "                    token = self.checkPrevState(currentState,c);\n",
    "                    if(token != None):\n",
    "                        return token\n",
    "                    \n",
    "                    self.text += c\n",
    "                # FOR SINGLE QUOTE STRING\n",
    "                elif(currentState==10 ): \n",
    "                    # CHECK IF THERE IS PREV STATE\n",
    "                    token = self.checkPrevState(currentState,c);\n",
    "                    if(token != None):\n",
    "                        return token\n",
    "                    \n",
    "                    self.text += c\n",
    "                # FOR NUMBER\n",
    "                elif(currentState==1 or currentState==3 or currentState==11 or currentState==2 or currentState==4 ): \n",
    "                    # CHECK IF THERE IS PREV STATE\n",
    "                    token = self.checkPrevState(currentState,c);\n",
    "                    if(token != None):\n",
    "                        return token\n",
    "                    \n",
    "                    self.text += c\n",
    "                    \n",
    "    def checkPrevState(self,currentState,c):\n",
    "        #FOR NUMBER\n",
    "        if((self.prevState == 1 or self.prevState == 4 or self.prevState == 11) and currentState != 1 \n",
    "           and currentState != 2 and currentState != 3 and currentState != 4 and currentState != 11):\n",
    "            self.notFirstRead = True\n",
    "            self.prevState = 0\n",
    "            self.lastRead -= 1\n",
    "            return Token(\"NUMBER\",\"NUMBER\",self.text)\n",
    "        # CHECH FOR NUMBER ERROR\n",
    "        elif((self.prevState == 3 and currentState!=4) or (self.prevState == 2 and currentState!=11)):\n",
    "            self.notFirstRead = True\n",
    "            self.prevState = 0\n",
    "            return Token(\"ERROR\",\"ERROR\",\"BADLY FORMED NUMBER\")\n",
    "        # FOR IDENTIFIER\n",
    "        elif(self.prevState == 8 and currentState != 8):\n",
    "            self.notFirstRead = True\n",
    "            self.prevState = 0\n",
    "            self.lastRead -= 1\n",
    "            return Token(\"IDENT\",\"IDENT\",self.text)\n",
    "        # FOR STRING SINGLE QUOTE\n",
    "        elif(self.prevState == 10 and currentState != 10):\n",
    "            self.notFirstRead = True\n",
    "            self.prevState = 0\n",
    "            self.text += c\n",
    "            return Token(\"STRING\",\"STRING\",self.text)\n",
    "        # FOR STRING DOUBLE QUOTE\n",
    "        elif(self.prevState == 9 and currentState != 9):\n",
    "            self.notFirstRead = True\n",
    "            self.prevState = 0\n",
    "            self.text += c\n",
    "            return Token(\"STRING\",\"STRING\",self.text)\n",
    "        # FOR SLASH\n",
    "        elif(self.prevState==6 and currentState != 6):\n",
    "            self.notFirstRead = True\n",
    "            self.lastRead -= 1\n",
    "            return Token(self.stringObj[\"/\"],self.stringObj[\"/\"],\"/\")\n",
    "        # FOR CHARACTER ASTERISK *\n",
    "        elif(self.prevState==5 and currentState != 5):\n",
    "            self.notFirstRead = True\n",
    "            self.lastRead -= 1\n",
    "            return Token(self.stringObj[\"*\"],self.stringObj[\"*\"],\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN LEXEME\n",
      "---------------------------------------------------\n",
      "NUMBER   10\n",
      "EXP   **\n",
      "NUMBER   2\n",
      "PLUS   +\n",
      "LPAREN   (\n",
      "NUMBER   4\n",
      "MULT   *\n",
      "NUMBER   5.5\n",
      "MULT   *\n",
      "LPAREN   (\n",
      "MINUS   -\n",
      "NUMBER   3\n",
      "RPAREN   )\n",
      "RPAREN   )\n",
      "EQUAL   =\n",
      "IDENT   SAVE\n",
      "NUMBER   1\n",
      "SCOLON   ;\n",
      "LPAREN   (\n",
      "MINUS   -\n",
      "NUMBER   10\n",
      "PLUS   +\n",
      "IDENT   SQRT\n",
      "LPAREN   (\n",
      "IDENT   RECALL\n",
      "LPAREN   (\n",
      "NUMBER   1\n",
      "RPAREN   )\n",
      "RPAREN   )\n",
      "RPAREN   )\n",
      "DIV   /\n",
      "LPAREN   (\n",
      "NUMBER   2\n",
      "MULT   *\n",
      "NUMBER   5.5\n",
      "RPAREN   )\n",
      "EQUAL   =\n",
      "IDENT   PRINT\n",
      "SCOLON   ;\n",
      "LPAREN   (\n",
      "MINUS   -\n",
      "NUMBER   10\n",
      "MINUS   -\n",
      "IDENT   SQRT\n",
      "LPAREN   (\n",
      "IDENT   RECALL\n",
      "LPAREN   (\n",
      "NUMBER   1\n",
      "RPAREN   )\n",
      "RPAREN   )\n",
      "RPAREN   )\n",
      "DIV   /\n",
      "LPAREN   (\n",
      "NUMBER   2\n",
      "MULT   *\n",
      "NUMBER   5.5\n",
      "RPAREN   )\n",
      "EQUAL   =\n",
      "IDENT   PRINT\n",
      "SCOLON   ;\n"
     ]
    }
   ],
   "source": [
    "#SAMPLE 1\n",
    "\n",
    "sample1 = LexicalAnalyzer(\"samp1.txt\")\n",
    "print(\"TOKEN LEXEME\")\n",
    "print(\"---------------------------------------------------\")\n",
    "\n",
    "token = sample1.process_token()\n",
    "while token.id != \"EOF\":\n",
    "  print(token.id, ' ', token.lexeme)\n",
    "  token = sample1.process_token()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN LEXEME\n",
      "---------------------------------------------------\n",
      "NUMBER   2\n",
      "STRING   'kinds'\n",
      "IDENT   of\n",
      "STRING   \"strings\"\n",
      "ADD   +\n",
      "MINUS   -\n",
      "MULT   *\n",
      "DIV   /\n",
      "MODULO   %\n",
      "EXP   **\n",
      "LPAREN   (\n",
      "RPAREN   )\n",
      "COMMA   ,\n",
      "SCOLON   ;\n",
      "EQUAL   =\n"
     ]
    }
   ],
   "source": [
    "#SAMPLE 2\n",
    "sample2 = LexicalAnalyzer(\"samp2.txt\")\n",
    "\n",
    "print(\"TOKEN LEXEME\")\n",
    "print(\"---------------------------------------------------\")\n",
    "token = sample2.process_token()\n",
    "while token.id != \"EOF\":\n",
    "  print(token.id, ' ', token.lexeme)\n",
    "  token = sample2.process_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN LEXEME\n",
      "---------------------------------------------------\n",
      "NUMBER   1.23e11\n",
      "IDENT   number\n",
      "NUMBER   1e+10\n",
      "IDENT   another\n",
      "IDENT   number\n",
      "MINUS   -\n",
      "NUMBER   2e-100\n",
      "IDENT   yet\n",
      "IDENT   another\n",
      "IDENT   number\n",
      "IDENT   error\n",
      "IDENT   characters\n",
      "IDENT   follow\n",
      "ERROR   ILLEGAL CHARACTER\n",
      "ERROR   ILLEGAL CHARACTER\n",
      "ERROR   UNTERMINATED STRING\n",
      "IDENT   two\n",
      "IDENT   of\n",
      "IDENT   them\n",
      "ERROR   UNTERMINATED STRING\n",
      "STRING   \"ok string\"\n",
      "IDENT   badly\n",
      "IDENT   formed\n",
      "IDENT   numbers\n",
      "IDENT   follow\n",
      "ERROR   ILLEGAL CHARACTER\n",
      "ERROR   BADLY FORMED NUMBER\n",
      "IDENT   gh\n",
      "ERROR   BADLY FORMED NUMBER\n",
      "IDENT   yz\n",
      "IDENT   these\n",
      "IDENT   are\n",
      "IDENT   not\n",
      "NUMBER   1e1\n",
      "IDENT   e\n",
      "NUMBER   1\n",
      "NUMBER   1234\n",
      "IDENT   a\n"
     ]
    }
   ],
   "source": [
    "#SAMPLE 3\n",
    "sample3 = LexicalAnalyzer(\"samp3.txt\")\n",
    "\n",
    "print(\"TOKEN LEXEME\")\n",
    "print(\"---------------------------------------------------\")\n",
    "token = sample3.process_token()\n",
    "while token.id != \"EOF\":\n",
    "  print(token.id, ' ', token.lexeme)\n",
    "  token = sample3.process_token()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
